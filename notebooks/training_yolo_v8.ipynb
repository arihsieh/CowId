{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v8 model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the base YOLO model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check graphics card availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set HOME path for console interaction as the root of the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.path.split(os.getcwd())[0]\n",
    "print(HOME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies for model, including Torch, Ultralytics packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check YOLO package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Torch installation and CUDA acceleration availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is available for systems with nvidia GPUs to enable training accelaration with graphics cards:\n",
    "# CUDA package: https://developer.nvidia.com/cuda-downloads\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with custom dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model is YOLOv8n, which is the most lightweight of all the YOLOv8 versions, with the least amount of params\n",
    "# The dataset is manually tagged and downloaded through roboflow, the .yaml file is used to identify all the train/test/val datasets\n",
    "\n",
    "%cd {HOME}\n",
    "\n",
    "!yolo task=detect mode=train model={HOME}/yolov8n.pt data={HOME}/data/CowID.v7i.yolov8/data.yaml epochs=40 imgsz=640 plots=True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training isn't completed in one session, it can be continued using the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !yolo detect train resume model=C:\\Users\\arihs\\Documents\\Thesis\\notebooks\\runs\\detect\\train18\\weights\\last.pt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "%cd {HOME}\n",
    "Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {HOME}\n",
    "Image(filename=f'{HOME}/runs/detect/train/results.png', width=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction using client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The console provide ways to predict videos, images, etc.\n",
    "\n",
    "%cd {HOME}\n",
    "\n",
    "!yolo task=detect mode=predict model={HOME}/runs/detect/train/weights/best.pt conf=0.5 source={HOME}/data/test_4.mp4 save=True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction using Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCV is a popular framework to work with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "HOME = os.path.split(os.getcwd())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "model = YOLO(f\"{HOME}/runs/detect/train/weights/best.pt\")\n",
    "\n",
    "# Make predictions based on images\n",
    "\n",
    "results = model.predict(source=f\"{HOME}/test_4_frames\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Siamese network dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a folder with images of cows, the model predicts the bounding boxes of the cows\n",
    "# and expand_rectangle_to_square changes the shape of the prediction to a square\n",
    "# then crop_to_square is used extract the cow from the image and save it\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "model = YOLO(f\"{HOME}/runs/detect/train/weights/best.pt\")\n",
    "\n",
    "img_dir = f'{HOME}/test_4_frames/'\n",
    "\n",
    "def expand_rectangle_to_square(x1, y1, x2, y2):\n",
    "    width = abs(x2 - x1)\n",
    "    height = abs(y2 - y1)\n",
    "    size = max(width, height)\n",
    "    center_x = (x1 + x2) / 2\n",
    "    center_y = (y1 + y2) / 2\n",
    "    new_x1 = center_x - size / 2\n",
    "    new_y1 = center_y - size / 2\n",
    "    new_x2 = center_x + size / 2\n",
    "    new_y2 = center_y + size / 2\n",
    "    return new_x1, new_y1, new_x2, new_y2\n",
    "\n",
    "def crop_to_square(image_path, x1, y1, x2, y2):\n",
    "    image = Image.open(image_path)\n",
    "    cropped_image = image.crop((x1, y1, x2, y2))\n",
    "    return cropped_image\n",
    "    \n",
    "    \n",
    "for number in range(len(os.listdir(img_dir))-1):\n",
    "    img_path = os.path.join(img_dir, f\"frame{number}.jpg\")\n",
    "    res = model(img_path, conf=0.5)\n",
    "    boxes = res[0].boxes.xyxy.tolist()\n",
    "    cow_number = 0\n",
    "    for inner_list in boxes:\n",
    "        cow_number += 1\n",
    "        x1, y1, x2, y2 = inner_list\n",
    "        x1, y1, x2, y2 = expand_rectangle_to_square(x1, y1, x2, y2)\n",
    "        cropped_image = crop_to_square(img_path, x1, y1, x2, y2)\n",
    "        cropped_image.save(os.path.join(f'{HOME}/output2/', f\"frame{number}-{cow_number}.jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6438490bf490893295c9d70690bd4cc7e870b32cd2d035ba0ba21a4561f0a6de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
