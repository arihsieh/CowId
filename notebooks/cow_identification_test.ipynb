{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess_input\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess_input\n",
    "from tensorflow.keras import layers, metrics, regularizers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications import ResNet152\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Code\\CowId\n"
     ]
    }
   ],
   "source": [
    "HOME = os.path.split(os.getcwd())[0]\n",
    "print(HOME)\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_images(encoder, cows_list1, cows_list2, threshold=0.5):\n",
    "    # Getting the encodings for the passed faces\n",
    "    tensor1 = encoder.predict(cows_list1)\n",
    "    tensor2 = encoder.predict(cows_list2)\n",
    "    \n",
    "    distance = np.sum(np.square(tensor1-tensor2), axis=-1)\n",
    "    prediction = np.where(distance<=threshold, 0, 1)\n",
    "    print(prediction)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path, target_size=(128, 128)):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs(output_loc, test_dataset_path):\n",
    "    pos_pairs, neg_pairs = [], []\n",
    "    for cows in os.listdir(test_dataset_path):\n",
    "        neg_dir_list = os.listdir(test_dataset_path)\n",
    "        neg_dir_list.remove(cows)\n",
    "        all_cows_except_current = []\n",
    "        for neg_cows in neg_dir_list:\n",
    "            neg_list = os.listdir(os.path.join(test_dataset_path, neg_cows))\n",
    "            neg_list = [os.path.join(test_dataset_path, neg_cows, x) for x in neg_list]\n",
    "            all_cows_except_current += neg_list\n",
    "        path_to_cow = os.path.join(test_dataset_path, cows)\n",
    "        print(path_to_cow)\n",
    "        if \"cow\" in path_to_cow:\n",
    "            pos_list = os.listdir(os.path.join(test_dataset_path, cows))\n",
    "            pos_list = [os.path.join(test_dataset_path, cows, x) for x in pos_list]\n",
    "            anchor_image = os.path.join(path_to_cow, 'anchor.jpg')\n",
    "            pos_pairs += [(anchor_image, x) for x in pos_list if x != anchor_image]\n",
    "            neg_pairs += [(anchor_image, x) for x in all_cows_except_current]\n",
    "    print(len(pos_pairs), len(neg_pairs))\n",
    "    with open(os.path.join(output_loc, 'pos_pairs.csv'), 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in pos_pairs:\n",
    "            writer.writerow(row)\n",
    "    with open(os.path.join(output_loc, 'neg_pairs.csv'), 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for row in neg_pairs:\n",
    "            writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_params(params, filename):\n",
    "    \"\"\"Saves parameters to a json file\"\"\"\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(params, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(base_folder, iteration):\n",
    "    \"\"\"Creates a new directory for storing data\"\"\"\n",
    "    new_dir = os.path.join(HOME, 'data', base_folder, str(iteration))\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "    return new_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_iteration(base_folder):\n",
    "    \"\"\"Determines the next iteration number based on existing directories\"\"\"\n",
    "    folder_names = [\n",
    "        int(name) for name in os.listdir(os.path.join(HOME, 'data', base_folder))\n",
    "        if os.path.isdir(os.path.join(HOME, 'data', base_folder, name))\n",
    "    ]\n",
    "    return 0 if len(folder_names) == 0 else max(folder_names) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(file_path):\n",
    "    \"\"\"Reads a dataset from a csv file and returns it as a list\"\"\"\n",
    "    with open(file_path, newline='') as file:\n",
    "        return list(csv.reader(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(tuples_list, batch_size=64, preprocess=True, encoder_architecture='resnet'):\n",
    "    batch_steps = len(tuples_list)//batch_size\n",
    "    \n",
    "    for i in range(batch_steps+1):\n",
    "        anchor   = []\n",
    "        comparison = []\n",
    "        \n",
    "        j = i*batch_size\n",
    "        while j<(i+1)*batch_size and j<len(tuples_list):\n",
    "            a, c = tuples_list[j]\n",
    "            anchor.append(read_image(a))\n",
    "            comparison.append(read_image(c))\n",
    "            j+=1\n",
    "            \n",
    "        anchor = np.array(anchor)\n",
    "        comparison = np.array(comparison)\n",
    "        \n",
    "        if preprocess:\n",
    "            if encoder_architecture == 'resnet':\n",
    "                anchor = resnet_preprocess_input(anchor)\n",
    "                comparison = resnet_preprocess_input(comparison)\n",
    "            elif encoder_architecture == 'xception':\n",
    "                anchor = xception_preprocess_input(anchor)\n",
    "                comparison = xception_preprocess_input(comparison)\n",
    "        \n",
    "        yield ([anchor, comparison])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(dataset, model, batch_size, threshold=0.5, encoder_architecture='resnet'):\n",
    "    \"\"\"Classifies images using the siamese model\"\"\"\n",
    "    result = np.array([])\n",
    "    for data in get_batch(dataset, batch_size=batch_size, preprocess=True, encoder_architecture=encoder_architecture):\n",
    "        a, c = data\n",
    "        result = np.append(result, classify_images(model, a, c, threshold))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true, pred, dir):\n",
    "    \n",
    "    # Compute and print the accuracy\n",
    "    print(f\"\\nAccuracy of model: {accuracy_score(true, pred)}\\n\")\n",
    "    \n",
    "    # Compute and plot the Confusion matrix\n",
    "    cf_matrix = confusion_matrix(true, pred)\n",
    "\n",
    "    categories  = ['Similar','Different']\n",
    "    names = ['True Similar','False Similar', 'False Different','True Different']\n",
    "    percentages = ['{0:.2%}'.format(value) for value in cf_matrix.flatten() / np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f'{v1}\\n{v2}' for v1, v2 in zip(names, percentages)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    plt.clf()\n",
    "    sns.heatmap(cf_matrix, annot = labels, cmap = 'Blues',fmt = '',\n",
    "                xticklabels = categories, yticklabels = categories)\n",
    "\n",
    "    plt.xlabel(\"Predicted\", fontdict = {'size':14}, labelpad = 10)\n",
    "    plt.ylabel(\"Actual\"   , fontdict = {'size':14}, labelpad = 10)\n",
    "    plt.title (\"Confusion Matrix\", fontdict = {'size':12}, pad = 20)\n",
    "    \n",
    "    plt.tight_layout()  # Adjust layout\n",
    "\n",
    "    plt.savefig(os.path.join(dir, 'confusion_matrix.png'))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"STORE_FOLDER\": \"optuna_siamese_runs_tests\",\n",
    "    \"TEST_DATASET_PATH\": os.path.join(HOME, \"data\", \"siamese_v8_augmented\", \"test\"),\n",
    "    \"SIAMESE_MODEL_LOC\": os.path.join(HOME, \"data\", \"optuna_siamese_runs\", \"148\")\n",
    "}\n",
    "\n",
    "def create_test_metrics():\n",
    "    siamese_run_iteration = get_next_iteration(params[\"STORE_FOLDER\"])\n",
    "    siamese_dir = create_dir(params[\"STORE_FOLDER\"], siamese_run_iteration)\n",
    "    generate_pairs(siamese_dir, params[\"TEST_DATASET_PATH\"])\n",
    "\n",
    "    pos_dataset = read_dataset(os.path.join(siamese_dir, \"pos_pairs.csv\"))\n",
    "    neg_dataset = read_dataset(os.path.join(siamese_dir, \"neg_pairs.csv\"))\n",
    "\n",
    "    with open(os.path.join(params[\"SIAMESE_MODEL_LOC\"], 'metrics.json'), 'r') as f:\n",
    "        training_metrics = json.load(f)\n",
    "        best_threshold = 16 # training_metrics['best_threshold']\n",
    "\n",
    "    with open(os.path.join(params[\"SIAMESE_MODEL_LOC\"], 'params.json'), 'r') as f:\n",
    "        training_params = json.load(f)\n",
    "        encoder_architecture = training_params['ARCHITECTURE']\n",
    "    \n",
    "    model_path = os.path.join(params[\"SIAMESE_MODEL_LOC\"], \"encoder.h5\")\n",
    "    encoder = load_model(model_path)\n",
    "    \n",
    "    pos_list = classify_data(pos_dataset, encoder, batch_size=256, threshold=best_threshold, encoder_architecture=encoder_architecture)\n",
    "    neg_list = classify_data(neg_dataset, encoder, batch_size=256, threshold=best_threshold,  encoder_architecture=encoder_architecture)\n",
    "\n",
    "    # Calculate overall accuracy\n",
    "    true_overall = np.array([0]*len(pos_list) + [1]*len(neg_list))\n",
    "    pred_overall = np.append(pos_list, neg_list)\n",
    "    print(f\"Accuracy of model overall: {accuracy_score(true_overall, pred_overall)}\")\n",
    "\n",
    "    # Calculate accuracy for positives\n",
    "    true_pos = np.array([0]*len(pos_list))\n",
    "    print(f\"Accuracy of model on positives: {accuracy_score(true_pos, pos_list)}\")\n",
    "\n",
    "    # Calculate accuracy for negatives\n",
    "    true_neg = np.array([1]*len(neg_list))\n",
    "    print(f\"Accuracy of model on negatives: {accuracy_score(true_neg, neg_list)}\")\n",
    "\n",
    "    # Add metrics to params\n",
    "    params[\"OVERALL_ACCURACY\"] = accuracy_score(true_overall, pred_overall)\n",
    "    params[\"POSITIVE_ACCURACY\"] = accuracy_score(true_pos, pos_list)\n",
    "    params[\"NEGATIVE_ACCURACY\"] = accuracy_score(true_neg, neg_list)\n",
    "    params[\"ARCHICTECTURE\"] = encoder_architecture\n",
    "    params[\"BEST_THRESHOLD\"] = best_threshold\n",
    "    # # Save results in a readable format, joining pred with true to one string and save a list of all results\n",
    "    # results = []\n",
    "    # for i in range(len(true_overall)):\n",
    "    #     results.append(f\"True: {true_overall[i]}, Pred: {pred_overall[i]}\")\n",
    "    # params[\"RESULTS\"] = results\n",
    "    \n",
    "\n",
    "    save_params(params, os.path.join(siamese_dir, \"params.json\"))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(true_overall, pred_overall, siamese_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Code\\CowId\\data\\siamese_v8_augmented\\test\\cow_22\n",
      "e:\\Code\\CowId\\data\\siamese_v8_augmented\\test\\cow_24\n",
      "e:\\Code\\CowId\\data\\siamese_v8_augmented\\test\\cow_3\n",
      "e:\\Code\\CowId\\data\\siamese_v8_augmented\\test\\cow_6\n",
      "e:\\Code\\CowId\\data\\siamese_v8_augmented\\test\\negatives\n",
      "171 1817\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "6/6 [==============================] - 1s 24ms/step\n",
      "6/6 [==============================] - 0s 17ms/step\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "8/8 [==============================] - 0s 41ms/step\n",
      "8/8 [==============================] - 0s 19ms/step\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "8/8 [==============================] - 0s 20ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "8/8 [==============================] - 0s 19ms/step\n",
      "8/8 [==============================] - 0s 18ms/step\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "8/8 [==============================] - 0s 50ms/step\n",
      "8/8 [==============================] - 0s 31ms/step\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1]\n",
      "8/8 [==============================] - 0s 43ms/step\n",
      "8/8 [==============================] - 0s 23ms/step\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0]\n",
      "8/8 [==============================] - 0s 15ms/step\n",
      "8/8 [==============================] - 0s 38ms/step\n",
      "[0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1]\n",
      "8/8 [==============================] - 0s 18ms/step\n",
      "8/8 [==============================] - 0s 28ms/step\n",
      "[0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1 0\n",
      " 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Accuracy of model overall: 0.9074446680080482\n",
      "Accuracy of model on positives: 0.7251461988304093\n",
      "Accuracy of model on negatives: 0.9246009906439185\n",
      "\n",
      "Accuracy of model: 0.9074446680080482\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_test_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
